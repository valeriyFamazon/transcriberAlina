import React, { useState, useRef, useEffect } from 'react';

function App() {
  const [isRecording, setIsRecording] = useState(false);
  const [transcriptionText, setTranscriptionText] = useState('');
  const [language, setLanguage] = useState('ru');
  const [audioSource, setAudioSource] = useState('microphone');
  const [engine, setEngine] = useState('openai');
  const [openaiPrompt, setOpenaiPrompt] = useState('–ó–∞–¥–∞—á–∞: —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∏—Ä–æ–≤–∞—Ç—å —Ç–æ–ª—å–∫–æ —Ä–µ—á—å —Å–ø–∏–∫–µ—Ä–∞ –∏–∑ –≤—Ö–æ–¥–Ω–æ–≥–æ –∞—É–¥–∏–æ. –¢—Ä–µ–±–æ–≤–∞–Ω–∏—è: 1) –ò–≥–Ω–æ—Ä–∏—Ä—É–π –ª—é–±—ã–µ –≤—Å—Ç–∞–≤–∫–∏, —Å—É–±—Ç–∏—Ç—Ä—ã, –∑–∞—Å—Ç–∞–≤–∫–∏ –∏ —Ñ—Ä–∞–∑—ã –≤—Ä–æ–¥–µ "–°—É–±—Ç–∏—Ç—Ä—ã –¥–µ–ª–∞–ª DimaTorzok", "–ü—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ —Å–ª–µ–¥—É–µ—Ç", "[–º—É–∑—ã–∫–∞]", "[–∞–ø–ª–æ–¥–∏—Å–º–µ–Ω—Ç—ã]". 2) –ù–µ –¥–æ–±–∞–≤–ª—è–π –Ω–∏—á–µ–≥–æ –æ—Ç —Å–µ–±—è. 3) –°–æ—Ö—Ä–∞–Ω—è–π –ø—É–Ω–∫—Ç—É–∞—Ü–∏—é –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ–π —Ä–µ—á–∏. 4) –°–æ—Ö—Ä–∞–Ω—è–π —è–∑—ã–∫ –∏—Å—Ö–æ–¥–Ω–æ–π —Ä–µ—á–∏. 5) –£–±–∏—Ä–∞–π —ç—ç—ç/–º–º–º/–º–µ–∂–¥–æ–º–µ—Ç–∏—è –∏ —à—É–º–æ–≤—ã–µ —Å–ª–æ–≤–∞.');
  const [systemCaptureMode, setSystemCaptureMode] = useState('device'); // 'device' | 'screen'
  const [status, setStatus] = useState('–ì–æ—Ç–æ–≤ –∫ —Ä–∞–±–æ—Ç–µ');
  const [error, setError] = useState('');
  const [isConnected, setIsConnected] = useState(false);
  const [availableDevices, setAvailableDevices] = useState([]);
  const [selectedDevice, setSelectedDevice] = useState('');
  const [selectedSystemDevice, setSelectedSystemDevice] = useState('');
  const [audioLevel, setAudioLevel] = useState(0);
  
  const mediaRecorderRef = useRef(null);
  const sendIntervalRef = useRef(null);
  const segmentedModeRef = useRef(false);
  const websocketRef = useRef(null);
  const streamRef = useRef(null);
  const chunksRef = useRef([]);
  const audioContextRef = useRef(null);
  const analyserRef = useRef(null);
  const levelIntervalRef = useRef(null);

  // –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ WebSocket
  useEffect(() => {
    connectWebSocket();
    return () => {
      if (websocketRef.current) {
        websocketRef.current.close();
      }
      if (streamRef.current) {
        streamRef.current.getTracks().forEach(track => track.stop());
      }
      stopAudioLevelMonitoring();
    };
  }, []);

  // –ü–æ–ª—É—á–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ –∞—É–¥–∏–æ —É—Å—Ç—Ä–æ–π—Å—Ç–≤
  useEffect(() => {
    getAudioDevices();
  }, []);

  const getAudioDevices = async () => {
    try {
      console.log('üîç –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ –∞—É–¥–∏–æ —É—Å—Ç—Ä–æ–π—Å—Ç–≤...');
      const devices = await navigator.mediaDevices.enumerateDevices();
      const audioInputs = devices.filter(device => device.kind === 'audioinput');
      const audioOutputs = devices.filter(device => device.kind === 'audiooutput');
      
      console.log(`üì± –ù–∞–π–¥–µ–Ω–æ –∞—É–¥–∏–æ —É—Å—Ç—Ä–æ–π—Å—Ç–≤: ${audioInputs.length}`);
      audioInputs.forEach((device, index) => {
        console.log(`üì± ${index + 1}. ${device.label || `–ú–∏–∫—Ä–æ—Ñ–æ–Ω ${index + 1}`} (${device.deviceId.substr(0, 8)})`);
      });
      
      setAvailableDevices([...audioInputs, ...audioOutputs]);
      
      // –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –≤—ã–±–∏—Ä–∞–µ–º –ø–µ—Ä–≤—ã–π –º–∏–∫—Ä–æ—Ñ–æ–Ω
      if (audioInputs.length > 0) {
        setSelectedDevice(audioInputs[0].deviceId);
        console.log(`‚úÖ –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –≤—ã–±—Ä–∞–Ω –º–∏–∫—Ä–æ—Ñ–æ–Ω: ${audioInputs[0].label || '–ü–µ—Ä–≤—ã–π –º–∏–∫—Ä–æ—Ñ–æ–Ω'}`);
      }
      if (audioOutputs.length > 0) {
        setSelectedSystemDevice(audioOutputs[0].deviceId);
        console.log(`‚úÖ –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –≤—ã–±—Ä–∞–Ω —Å–∏—Å—Ç–µ–º–Ω—ã–π –∏—Å—Ç–æ—á–Ω–∏–∫: ${audioOutputs[0].label || '–ü–µ—Ä–≤—ã–π –≤—ã—Ö–æ–¥'}`);
      }
    } catch (error) {
      console.error('‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —É—Å—Ç—Ä–æ–π—Å—Ç–≤:', error);
      setError('–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ –º–∏–∫—Ä–æ—Ñ–æ–Ω–æ–≤');
    }
  };

  const startAudioLevelMonitoring = (stream) => {
    try {
      audioContextRef.current = new (window.AudioContext || window.webkitAudioContext)();
      analyserRef.current = audioContextRef.current.createAnalyser();
      const microphone = audioContextRef.current.createMediaStreamSource(stream);
      
      analyserRef.current.fftSize = 256;
      microphone.connect(analyserRef.current);
      
      const bufferLength = analyserRef.current.frequencyBinCount;
      const dataArray = new Uint8Array(bufferLength);
      
      levelIntervalRef.current = setInterval(() => {
        analyserRef.current.getByteFrequencyData(dataArray);
        
        let sum = 0;
        for (let i = 0; i < bufferLength; i++) {
          sum += dataArray[i];
        }
        const average = sum / bufferLength;
        const percentage = Math.round((average / 255) * 100);
        
        setAudioLevel(percentage);
      }, 100);
      
      console.log('‚úÖ –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ —É—Ä–æ–≤–Ω—è –∑–≤—É–∫–∞ –∑–∞–ø—É—â–µ–Ω');
    } catch (error) {
      console.error('‚ùå –û—à–∏–±–∫–∞ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ —É—Ä–æ–≤–Ω—è:', error);
    }
  };

  const stopAudioLevelMonitoring = () => {
    if (levelIntervalRef.current) {
      clearInterval(levelIntervalRef.current);
      levelIntervalRef.current = null;
    }
    if (audioContextRef.current) {
      audioContextRef.current.close();
      audioContextRef.current = null;
    }
    setAudioLevel(0);
  };

  const connectWebSocket = () => {
    try {
      websocketRef.current = new WebSocket('ws://localhost:8001/ws');
      
      websocketRef.current.onopen = () => {
        console.log('üîó WebSocket –ø–æ–¥–∫–ª—é—á–µ–Ω');
        setIsConnected(true);
        setStatus('–ü–æ–¥–∫–ª—é—á–µ–Ω–æ –∫ —Å–µ—Ä–≤–µ—Ä—É');
        setError('');
      };

      websocketRef.current.onmessage = (event) => {
        try {
          const data = JSON.parse(event.data);
          console.log('üì® –ü–æ–ª—É—á–µ–Ω–æ —Å–æ–æ–±—â–µ–Ω–∏–µ:', data);
          
          if (data.text) {
            setTranscriptionText(prev => {
              const newText = prev + '\n' + data.text;
              return newText;
            });
            setStatus('–ü–æ–ª—É—á–µ–Ω —Ç–µ–∫—Å—Ç —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏');
          } else if (data.error) {
            setError(data.error);
            setStatus('–û—à–∏–±–∫–∞ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏');
          } else if (data.status) {
            setStatus(data.status);
          }
        } catch (error) {
          console.error('‚ùå –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ —Å–æ–æ–±—â–µ–Ω–∏—è:', error);
        }
      };

      websocketRef.current.onclose = () => {
        setIsConnected(false);
        setStatus('–°–æ–µ–¥–∏–Ω–µ–Ω–∏–µ —Ä–∞–∑–æ—Ä–≤–∞–Ω–æ');
        setTimeout(connectWebSocket, 3000); // –ü–µ—Ä–µ–ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ —á–µ—Ä–µ–∑ 3 —Å–µ–∫—É–Ω–¥—ã
      };

      websocketRef.current.onerror = (error) => {
        setError('–û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ —Å–µ—Ä–≤–µ—Ä—É');
        setIsConnected(false);
      };
    } catch (err) {
      setError('–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–∫–ª—é—á–∏—Ç—å—Å—è –∫ —Å–µ—Ä–≤–µ—Ä—É');
      setIsConnected(false);
    }
  };

  const startRecording = async () => {
    try {
      console.log('üé§ –ù–∞—á–∏–Ω–∞–µ–º –∑–∞–ø–∏—Å—å...');
      console.log('üì° WebSocket —Å–æ—Å—Ç–æ—è–Ω–∏–µ:', websocketRef.current?.readyState);
      setError('');
      setTranscriptionText('');
      
      // –ù–∞—Å—Ç—Ä–æ–π–∫–∞ constraints —Å –≤—ã–±—Ä–∞–Ω–Ω—ã–º —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ–º
      // –ü–æ–¥–¥–µ—Ä–∂–∫–∞ –∏—Å—Ç–æ—á–Ω–∏–∫–∞ "–º–∏–∫—Ä–æ—Ñ–æ–Ω + —Å–∏—Å—Ç–µ–º–Ω—ã–π –∑–≤—É–∫" (mix)
      let stream;
      if (audioSource === 'both') {
        const mic = await navigator.mediaDevices.getUserMedia({ audio: { deviceId: selectedDevice ? { exact: selectedDevice } : undefined, echoCancellation: true, noiseSuppression: true, autoGainControl: true } });
        let sys;
        if (systemCaptureMode === 'screen') {
          try {
            const disp = await navigator.mediaDevices.getDisplayMedia({ audio: true, video: true });
            // –û—Ç–∫–ª—é—á–∏–º –≤–∏–¥–µ–æ, –æ—Å—Ç–∞–≤–∏–º —Ç–æ–ª—å–∫–æ –∞—É–¥–∏–æ
            disp.getVideoTracks().forEach(t => t.stop());
            sys = disp;
          } catch (e) {
            console.error('‚ùå getDisplayMedia –Ω–µ —É–¥–∞–ª–æ—Å—å, fallback –Ω–∞ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ', e);
            sys = await navigator.mediaDevices.getUserMedia({ audio: { deviceId: selectedSystemDevice ? { exact: selectedSystemDevice } : undefined } });
          }
        } else {
          sys = await navigator.mediaDevices.getUserMedia({ audio: { deviceId: selectedSystemDevice ? { exact: selectedSystemDevice } : undefined } });
        }
        const ctx = new (window.AudioContext || window.webkitAudioContext)();
        const dest = ctx.createMediaStreamDestination();
        const micNode = ctx.createMediaStreamSource(mic);
        const sysNode = ctx.createMediaStreamSource(sys);
        micNode.connect(dest);
        sysNode.connect(dest);
        // –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º dest –≤ –º–æ–Ω–æ
        const mix = dest.stream;
        stream = mix;
      } else {
        if (audioSource === 'system') {
          if (systemCaptureMode === 'screen') {
            try {
              const disp = await navigator.mediaDevices.getDisplayMedia({ audio: true, video: true });
              disp.getVideoTracks().forEach(t => t.stop());
              stream = disp;
            } catch (e) {
              console.error('‚ùå getDisplayMedia –Ω–µ —É–¥–∞–ª–æ—Å—å –¥–ª—è system', e);
              stream = await navigator.mediaDevices.getUserMedia({ audio: { deviceId: selectedSystemDevice ? { exact: selectedSystemDevice } : undefined } });
            }
          } else {
            stream = await navigator.mediaDevices.getUserMedia({ audio: { deviceId: selectedSystemDevice ? { exact: selectedSystemDevice } : undefined } });
          }
        } else {
        stream = await navigator.mediaDevices.getUserMedia({
          audio: {
            deviceId: selectedDevice ? { exact: selectedDevice } : undefined,
            sampleRate: 16000,
            channelCount: 1,
            echoCancellation: true,
            noiseSuppression: true,
            autoGainControl: true
          }
        });
        }
      }

      streamRef.current = stream;
      console.log('‚úÖ –î–æ—Å—Ç—É–ø –∫ –º–∏–∫—Ä–æ—Ñ–æ–Ω—É –ø–æ–ª—É—á–µ–Ω');

      // –ó–∞–ø—É—Å–∫–∞–µ–º –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ —É—Ä–æ–≤–Ω—è –∑–≤—É–∫–∞
      startAudioLevelMonitoring(stream);

      // –£–≤–µ–¥–æ–º–ª—è–µ–º —Å–µ—Ä–≤–µ—Ä –æ –Ω–∞—á–∞–ª–µ –∑–∞–ø–∏—Å–∏
      if (websocketRef.current && websocketRef.current.readyState === WebSocket.OPEN) {
        websocketRef.current.send(JSON.stringify({
          type: 'start',
          language: language,
          audioSource: audioSource,
          engine: engine,
          prompt: engine === 'openai' ? openaiPrompt : undefined
        }));
      }
      const options = { audioBitsPerSecond: 128000 };
      const preferredFormats = [
        'audio/ogg;codecs=opus',
        'audio/webm;codecs=opus',
        'audio/webm',
        'audio/mp4'
      ];
      for (const fmt of preferredFormats) {
        if (MediaRecorder.isTypeSupported(fmt)) {
          options.mimeType = fmt;
          console.log(`‚úÖ –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ñ–æ—Ä–º–∞—Ç: ${fmt}`);
          break;
        }
      }

      segmentedModeRef.current = true;
      const startSegment = () => {
        if (!segmentedModeRef.current) return;
        const mr = new MediaRecorder(stream, options);
        mediaRecorderRef.current = mr;
        console.log('‚úÖ MediaRecorder —Å–µ–≥–º–µ–Ω—Ç —Å–æ–∑–¥–∞–Ω —Å mimeType:', mr.mimeType);
        mr.ondataavailable = (event) => {
          if (event.data && event.data.size > 0) {
            const reader = new FileReader();
            reader.onload = () => {
              const base64Data = String(reader.result).split(',')[1] || '';
              if (websocketRef.current && websocketRef.current.readyState === WebSocket.OPEN) {
                websocketRef.current.send(JSON.stringify({
                  type: 'audio',
                  data: base64Data,
                  format: event.data.type,
                  language: language
                }));
              }
            };
            reader.readAsDataURL(event.data);
          }
        };
        mr.onerror = (event) => {
          console.error('‚ùå –û—à–∏–±–∫–∞ MediaRecorder:', event);
          setError('–û—à–∏–±–∫–∞ –∑–∞–ø–∏—Å–∏ –∞—É–¥–∏–æ');
          segmentedModeRef.current = false;
          try { mr.stop(); } catch (_) {}
          stopRecording();
        };
        mr.onstop = () => {
          if (segmentedModeRef.current) {
            setTimeout(startSegment, 0);
          }
        };
        mr.start();
        // –ó–∞–∫—Ä—ã–≤–∞–µ–º –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä –∏ –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º —Å–∞–º–æ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω—ã–π Blob
        setTimeout(() => {
          if (mr.state === 'recording') {
            try { mr.stop(); } catch (_) {}
          }
        }, 2000);
      };
      startSegment();
      setIsRecording(true);
      setStatus('–ó–∞–ø–∏—Å—å –Ω–∞—á–∞–ª–∞—Å—å...');

    } catch (err) {
      console.error('‚ùå –û—à–∏–±–∫–∞ –∑–∞–ø—É—Å–∫–∞ –∑–∞–ø–∏—Å–∏:', err);
      setError('–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –¥–æ—Å—Ç—É–ø –∫ –º–∏–∫—Ä–æ—Ñ–æ–Ω—É: ' + err.message);
      setStatus('–û—à–∏–±–∫–∞ –¥–æ—Å—Ç—É–ø–∞ –∫ –º–∏–∫—Ä–æ—Ñ–æ–Ω—É');
    }
  };

  const stopRecording = () => {
    if (mediaRecorderRef.current && mediaRecorderRef.current.state !== 'inactive') {
      mediaRecorderRef.current.stop();
    }

    if (streamRef.current) {
      streamRef.current.getTracks().forEach(track => track.stop());
      streamRef.current = null;
    }

    stopAudioLevelMonitoring();

    // –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Å–µ–≥–º–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω—É—é –∑–∞–ø–∏—Å—å
    segmentedModeRef.current = false;
    if (mediaRecorderRef.current && mediaRecorderRef.current.state === 'recording') {
      try { mediaRecorderRef.current.stop(); } catch (_) {}
    }

    // –£–≤–µ–¥–æ–º–ª—è–µ–º —Å–µ—Ä–≤–µ—Ä –æ–± –æ—Å—Ç–∞–Ω–æ–≤–∫–µ –∑–∞–ø–∏—Å–∏
    if (websocketRef.current && websocketRef.current.readyState === WebSocket.OPEN) {
      websocketRef.current.send(JSON.stringify({
        type: 'stop'
      }));
    }

    setIsRecording(false);
    setStatus('–ó–∞–ø–∏—Å—å –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞');
  };

  const copyText = async () => {
    if (transcriptionText.trim()) {
      try {
        await navigator.clipboard.writeText(transcriptionText);
        setStatus('–¢–µ–∫—Å—Ç —Å–∫–æ–ø–∏—Ä–æ–≤–∞–Ω –≤ –±—É—Ñ–µ—Ä –æ–±–º–µ–Ω–∞');
      } catch (err) {
        setError('–ù–µ —É–¥–∞–ª–æ—Å—å —Å–∫–æ–ø–∏—Ä–æ–≤–∞—Ç—å —Ç–µ–∫—Å—Ç');
      }
    }
  };

  const clearText = () => {
    setTranscriptionText('');
    setStatus('–¢–µ–∫—Å—Ç –æ—á–∏—â–µ–Ω');
  };

  const getLanguageName = (code) => {
    const languages = {
      'ru': '–†—É—Å—Å–∫–∏–π',
      'en': 'English',
      'uk': '–£–∫—Ä–∞—ó–Ω—Å—å–∫–∞'
    };
    return languages[code] || code;
  };

  const getAudioSourceName = (source) => {
    const sources = {
      'microphone': '–ú–∏–∫—Ä–æ—Ñ–æ–Ω',
      'system': '–°–∏—Å—Ç–µ–º–Ω—ã–π –∑–≤—É–∫'
    };
    return sources[source] || source;
  };

  return (
    <div className="app">
      <div className="header">
        <h1>üé§ –¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ç–æ—Ä —Ä–µ—á–∏</h1>
        <p>–ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ —Ä–µ—á–∏ –≤ —Ç–µ–∫—Å—Ç –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏ —Å —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ–º —Å–ø–∏–∫–µ—Ä–æ–≤</p>
      </div>

      <div className="controls">
        <div className="control-group">
          <label>–Ø–∑—ã–∫ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è:</label>
          <select 
            value={language} 
            onChange={(e) => setLanguage(e.target.value)}
            disabled={isRecording}
          >
            <option value="ru">–†—É—Å—Å–∫–∏–π</option>
            <option value="en">English</option>
            <option value="uk">–£–∫—Ä–∞—ó–Ω—Å—å–∫–∞</option>
          </select>
        </div>

        <div className="control-group">
          <label>–ò—Å—Ç–æ—á–Ω–∏–∫ –∞—É–¥–∏–æ:</label>
          <select 
            value={audioSource} 
            onChange={(e) => setAudioSource(e.target.value)}
            disabled={isRecording}
          >
            <option value="microphone">–ú–∏–∫—Ä–æ—Ñ–æ–Ω</option>
            <option value="system">–°–∏—Å—Ç–µ–º–Ω—ã–π –∑–≤—É–∫</option>
            <option value="both">–ú–∏–∫—Ä–æ—Ñ–æ–Ω + –°–∏—Å—Ç–µ–º–Ω—ã–π –∑–≤—É–∫</option>
          </select>
        </div>

        {audioSource === 'both' && (
          <div className="control-group">
            <label>–£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ —Å–∏—Å—Ç–µ–º–Ω–æ–≥–æ –∑–≤—É–∫–∞ (VB-Cable –∏ —Ç.–ø.):</label>
            <select
              value={selectedSystemDevice}
              onChange={(e) => setSelectedSystemDevice(e.target.value)}
              disabled={isRecording}
            >
              {availableDevices.map((device, index) => (
                <option key={device.deviceId} value={device.deviceId}>
                  {device.label || `–ò—Å—Ç–æ—á–Ω–∏–∫ ${index + 1}`}
                </option>
              ))}
            </select>
          </div>
        )}

        <div className="control-group">
          <label>–î–≤–∏–∂–æ–∫ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è:</label>
          <select 
            value={engine}
            onChange={(e) => setEngine(e.target.value)}
            disabled={isRecording}
          >
            <option value="openai">OpenAI Whisper API</option>
            <option value="local">–õ–æ–∫–∞–ª—å–Ω–∞—è HF –º–æ–¥–µ–ª—å</option>
          </select>
        </div>

        {engine === 'openai' && (
          <div className="control-group" style={{minWidth: '320px'}}>
            <label>–ü—Ä–æ–º–ø—Ç –¥–ª—è OpenAI:</label>
            <textarea
              value={openaiPrompt}
              onChange={(e) => setOpenaiPrompt(e.target.value)}
              rows="3"
              disabled={isRecording}
            />
          </div>
        )}

        <div className="control-group">
          <label>–ú–∏–∫—Ä–æ—Ñ–æ–Ω:</label>
          <select 
            value={selectedDevice} 
            onChange={(e) => setSelectedDevice(e.target.value)}
            disabled={isRecording}
          >
            {availableDevices.map((device, index) => (
              <option key={device.deviceId} value={device.deviceId}>
                {device.label || `–ú–∏–∫—Ä–æ—Ñ–æ–Ω ${index + 1}`}
              </option>
            ))}
          </select>
        </div>

        <button
          className={`record-button ${isRecording ? 'stop' : 'start'}`}
          onClick={isRecording ? stopRecording : startRecording}
          disabled={!isConnected}
        >
          {isRecording ? '‚èπ –û—Å—Ç–∞–Ω–æ–≤–∏—Ç—å' : 'üéô –ù–∞—á–∞—Ç—å –∑–∞–ø–∏—Å—å'}
        </button>
      </div>

      {isRecording && (
        <div className="audio-level">
          <label>–£—Ä–æ–≤–µ–Ω—å –∑–≤—É–∫–∞:</label>
          <div className="level-meter">
            <div 
              className="level-bar" 
              style={{ width: `${audioLevel}%` }}
            ></div>
            <span className="level-text">{audioLevel}%</span>
          </div>
        </div>
      )}

      <div className="status-bar">
        <p>–°—Ç–∞—Ç—É—Å: {status}</p>
        {error && <p className="error">–û—à–∏–±–∫–∞: {error}</p>}
      </div>

      <div className="transcription-area">
        <h2>–¢–µ–∫—Å—Ç —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è:</h2>
        <textarea
          value={transcriptionText}
          onChange={(e) => setTranscriptionText(e.target.value)}
          rows="10"
          cols="50"
          placeholder="–¢–µ–∫—Å—Ç —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è –±—É–¥–µ—Ç –æ—Ç–æ–±—Ä–∞–∂–∞—Ç—å—Å—è –∑–¥–µ—Å—å..."
        />
        <button onClick={copyText}>–°–∫–æ–ø–∏—Ä–æ–≤–∞—Ç—å —Ç–µ–∫—Å—Ç</button>
        <button onClick={clearText}>–û—á–∏—Å—Ç–∏—Ç—å —Ç–µ–∫—Å—Ç</button>
      </div>
    </div>
  );
}

export default App;